<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>CineCam Pro (Next Gen)</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/tweakpane@3.1.0/dist/tweakpane.min.js"></script>
    <style>
        :root {
            --bg: #111;
            --surface: #1d1d1d;
            --primary: #269dff;
            --text: #f0f0f0;
            --border: #333;
        }
        #cinematic-bars {
            position: absolute;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            pointer-events: none;
        }
        #cinematic-bars .bar {
            background: black;
            width: 100%;
            height: 0; /* Controlled by JS */
            transition: height 0.3s ease;
        }
        #ui-buttons {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            z-index: 100;
        }
        #ui-buttons button {
            background: rgba(0,0,0,0.4);
            border: 1px solid var(--border);
            color: var(--text);
            font-family: inherit;
            font-size: 16px;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            backdrop-filter: blur(5px);
        }
        #ui-buttons button.recording {
            background: #e74c3c;
            border-color: #c0392b;
        }
        body {
            margin: 0;
            height: 100vh;
            background-color: var(--bg);
            color: var(--text);
            font-family: 'Inter', sans-serif;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }
        main {
            position: relative;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        canvas#display {
            width: 100%;
            height: 100%;
            object-fit: contain;
        }
        .tp-dfwv { /* Tweakpane custom class */
            width: 300px !important;
            position: absolute !important;
            right: 20px;
            top: 20px;
        }
    </style>
</head>
<body>
    <main>
        <canvas id="display"></canvas>
        <div id="cinematic-bars">
            <div class="bar"></div>
            <div class="bar"></div>
        </div>
        <div id="ui-buttons">
            <button id="capture-photo">Capture</button>
            <button id="record-video">Record</button>
        </div>
        <video id="video-source" autoplay playsinline muted style="display:none;"></video>
    </main>

    <!--
      This is a ground-up rewrite focusing on a robust, creative, and efficient architecture.
      All logic is encapsulated in the `VirtualCamera` class.
      Shaders are embedded directly for maximum control and performance.
    -->

    <!-- =========== SHADERS =========== -->
    <!-- Vertex Shader: Positions the video frame -->
    <script id="vertex-shader" type="x-shader/x-vertex">
        attribute vec2 a_position;
        attribute vec2 a_texCoord;
        varying vec2 v_texCoord;
        void main() {
            gl_Position = vec4(a_position, 0, 1);
            v_texCoord = a_texCoord;
        }
    </script>

    <!-- Fragment Shader: The "Uber" shader for all visual effects -->
    <script id="fragment-shader" type="x-shader/x-fragment">
        precision mediump float;
        varying vec2 v_texCoord;
        uniform sampler2D u_texture;

        // Effect Parameters
        uniform float u_contrast;
        uniform float u_exposure;
        uniform float u_saturation;
        uniform float u_sharpness;
        uniform float u_temperature;
        uniform float u_tint;
        uniform bool u_cinematicLook;
        uniform vec2 u_resolution;

        // Helper to convert temperature (K) to RGB
        vec3 kelvinToRGB(float kelvin) {
            vec3 color = vec3(1.0);
            kelvin /= 100.0;
            // Red
            if (kelvin <= 66.0) color.r = 1.0;
            else color.r = pow(kelvin - 60.0, -0.1332047592) * 329.698727446 / 255.0;
            // Green
            if (kelvin <= 66.0) color.g = (99.4708025861 * log(kelvin) - 161.1195681661) / 255.0;
            else color.g = pow(kelvin - 60.0, -0.0755148492) * 288.1221695283 / 255.0;
            // Blue
            if (kelvin >= 66.0) color.b = 1.0;
            else if (kelvin <= 19.0) color.b = 0.0;
            else color.b = (138.5177312231 * log(kelvin - 10.0) - 305.0447927307) / 255.0;
            return clamp(color, 0.0, 1.0);
        }

        // 3D LUT for Teal & Orange look
        vec3 cinematicLUT(vec3 color) {
            // A simple, simulated 3D LUT for a teal and orange look
            float blue = color.b * 15.0;
            float orange = (color.r + color.g) * 0.5 * 15.0;

            vec2 blue_orange = vec2(blue, orange);

            vec3 teal = vec3(0.0, 0.5, 0.5);
            vec3 orange_color = vec3(1.0, 0.7, 0.0);

            float luma = dot(color, vec3(0.2126, 0.7152, 0.0722));
            vec3 result = mix(teal, orange_color, luma);

            return mix(color, result, 0.5);
        }

        void main() {
            vec4 color = texture2D(u_texture, v_texCoord);

            // 1. White Balance (Temperature & Tint)
            vec3 tempRGB = kelvinToRGB(u_temperature);
            color.rgb *= tempRGB;
            color.g += u_tint; // Simple green/magenta tint

            // 2. Exposure
            color.rgb = pow(color.rgb, vec3(1.0 / (1.0 + u_exposure)));

            // 3. Contrast
            color.rgb = (color.rgb - 0.5) * u_contrast + 0.5;

            // 4. Saturation
            float luma = dot(color.rgb, vec3(0.2126, 0.7152, 0.0722));
            color.rgb = mix(vec3(luma), color.rgb, u_saturation);

            // 5. Sharpness (simple kernel)
            if (u_sharpness > 0.0) {
                vec2 pixel = 1.0 / u_resolution;
                float center = texture2D(u_texture, v_texCoord).g;
                float up = texture2D(u_texture, v_texCoord + vec2(0.0, pixel.y)).g;
                float down = texture2D(u_texture, v_texCoord - vec2(0.0, pixel.y)).g;
                float left = texture2D(u_texture, v_texCoord - vec2(pixel.x, 0.0)).g;
                float right = texture2D(u_texture, v_texCoord + vec2(pixel.x, 0.0)).g;
                float sharpened = (center * 5.0) - (up + down + left + right);
                color.rgb = mix(color.rgb, vec3(sharpened), u_sharpness);
            }

            // 6. Cinematic Look
            if (u_cinematicLook) {
                color.rgb = cinematicLUT(color.rgb);
            }

            gl_FragColor = clamp(color, 0.0, 1.0);
        }
    </script>


    <script>
    class VirtualCamera {
        constructor() {
            // --- DOM & Core Elements ---
            this.video = document.getElementById('video-source');
            this.canvas = document.getElementById('display');
            this.gl = this.canvas.getContext('webgl');

            // --- State ---
            this.stream = null;
            this.isRendering = false;

            // --- Parameters ---
            this.params = {
                // Color Lab
                exposure: 0.0,
                contrast: 1.0,
                saturation: 1.0,
                temperature: 6500,
                tint: 0.0,

                // Lens Kit
                sharpness: 0.5,

                // Overlays
                cinematicBars: true,

                // Master Toggle
                cinematicLook: true,
            };

            console.log("VirtualCamera initialized. Ready to start.");
        }

        async start() {
            console.log("Starting camera...");
            if (this.stream) this.stream.getTracks().forEach(track => track.stop());

            try {
                const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const videoStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1920 },
                        height: { ideal: 1080 },
                        facingMode: 'environment'
                    }
                });

                this.stream = new MediaStream([...videoStream.getVideoTracks(), ...audioStream.getAudioTracks()]);
                this.video.srcObject = this.stream;

                this.video.onloadedmetadata = () => {
                    console.log("Video metadata loaded. Setting up.");
                    this.gl.canvas.width = this.video.videoWidth;
                    this.gl.canvas.height = this.video.videoHeight;
                    this.setupWebGL();
                    this.setupUI();
                    this.setupNativeControls();
                    this.setupCaptureButtons();
                    if (!this.isRendering) {
                        this.isRendering = true;
                        this.render();
                    }
                };
            } catch (err) {
                console.error("Failed to start camera:", err);
                alert("Could not access camera. Please ensure permissions are granted.");
            }
        }

        setupWebGL() {
            const gl = this.gl;

            // 1. Compile shaders
            const vertexShader = this.compileShader(gl.VERTEX_SHADER, document.getElementById('vertex-shader').textContent);
            const fragmentShader = this.compileShader(gl.FRAGMENT_SHADER, document.getElementById('fragment-shader').textContent);

            // 2. Create and link program
            this.program = gl.createProgram();
            gl.attachShader(this.program, vertexShader);
            gl.attachShader(this.program, fragmentShader);
            gl.linkProgram(this.program);
            if (!gl.getProgramParameter(this.program, gl.LINK_STATUS)) {
                console.error("Could not link shaders:", gl.getProgramInfoLog(this.program));
                return;
            }
            gl.useProgram(this.program);

            // 3. Look up attribute and uniform locations
            this.locations = {
                attributes: {
                    position: gl.getAttribLocation(this.program, 'a_position'),
                    texCoord: gl.getAttribLocation(this.program, 'a_texCoord'),
                },
                uniforms: {
                    texture: gl.getUniformLocation(this.program, 'u_texture'),
                    resolution: gl.getUniformLocation(this.program, 'u_resolution'),
                    contrast: gl.getUniformLocation(this.program, 'u_contrast'),
                    exposure: gl.getUniformLocation(this.program, 'u_exposure'),
                    saturation: gl.getUniformLocation(this.program, 'u_saturation'),
                    sharpness: gl.getUniformLocation(this.program, 'u_sharpness'),
                    temperature: gl.getUniformLocation(this.program, 'u_temperature'),
                    tint: gl.getUniformLocation(this.program, 'u_tint'),
                    cinematicLook: gl.getUniformLocation(this.program, 'u_cinematicLook'),
                },
            };

            // 4. Set up vertex buffer for a plane
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]), gl.STATIC_DRAW);
            gl.enableVertexAttribArray(this.locations.attributes.position);
            gl.vertexAttribPointer(this.locations.attributes.position, 2, gl.FLOAT, false, 0, 0);

            const texCoordBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 0, 1, 0, 0, 1, 1, 1]), gl.STATIC_DRAW);
            gl.enableVertexAttribArray(this.locations.attributes.texCoord);
            gl.vertexAttribPointer(this.locations.attributes.texCoord, 2, gl.FLOAT, false, 0, 0);

            // 5. Create video texture
            this.texture = this.createTexture();

            console.log("WebGL setup complete.");
        }

        compileShader(type, source) {
            const gl = this.gl;
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(`An error occurred compiling the ${type === gl.VERTEX_SHADER ? "vertex" : "fragment"} shader:`, gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        createTexture() {
            const gl = this.gl;
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            return texture;
        }

        setupUI() {
            const pane = new Tweakpane.Pane({ title: 'CineCam Pro' });
            this.pane = pane;

            // --- Master Cinematic Toggle ---
            pane.addInput(this.params, 'cinematicLook', { label: 'Cinematic Look' });

            // --- Manual Control Folders (initially hidden) ---
            const colorFolder = pane.addFolder({ title: 'Color Lab', hidden: this.params.cinematicLook });
            const lensFolder = pane.addFolder({ title: 'Lens Kit', hidden: this.params.cinematicLook });

            // Link the visibility of folders to the master toggle
            pane.on('change', (ev) => {
                if (ev.presetKey === 'cinematicLook') {
                    colorFolder.hidden = ev.value;
                    lensFolder.hidden = ev.value;
                }
            });

            // --- Color Lab Controls ---
            colorFolder.addInput(this.params, 'exposure', { min: -1.0, max: 1.0, step: 0.01 });
            colorFolder.addInput(this.params, 'contrast', { min: 0.0, max: 2.0, step: 0.01 });
            colorFolder.addInput(this.params, 'saturation', { min: 0.0, max: 2.0, step: 0.01 });
            colorFolder.addInput(this.params, 'temperature', { min: 2000, max: 10000, step: 100 });
            colorFolder.addInput(this.params, 'tint', { min: -0.1, max: 0.1, step: 0.005 });

            // --- Lens Kit Controls ---
            lensFolder.addInput(this.params, 'sharpness', { min: 0.0, max: 2.0, step: 0.05 });

            // --- Overlays ---
            const overlayFolder = pane.addFolder({ title: 'Overlays' });
            overlayFolder.addInput(this.params, 'cinematicBars', { label: 'Cinematic Bars' });

            // We will add native controls and settings to their own folders later.
            console.log("UI setup complete.");
        }

        setupNativeControls() {
            const track = this.stream.getVideoTracks()[0];
            if (!track) return;

            const capabilities = track.getCapabilities();
            const settings = track.getSettings();

            const nativeFolder = this.pane.addFolder({ title: 'Native Controls', expanded: false });

            if (capabilities.exposureCompensation) {
                nativeFolder.addInput(settings, 'exposureCompensation', {
                    min: capabilities.exposureCompensation.min,
                    max: capabilities.exposureCompensation.max,
                    step: capabilities.exposureCompensation.step,
                    label: 'EV Comp'
                }).on('change', ev => track.applyConstraints({ advanced: [{ exposureCompensation: ev.value }] }));
            }
            if (capabilities.iso) {
                 nativeFolder.addInput(settings, 'iso', {
                    min: capabilities.iso.min,
                    max: capabilities.iso.max,
                    step: capabilities.iso.step,
                    label: 'ISO'
                }).on('change', ev => track.applyConstraints({ advanced: [{ iso: ev.value }] }));
            }
            if (capabilities.focusDistance) {
                nativeFolder.addInput(settings, 'focusDistance', {
                    min: capabilities.focusDistance.min,
                    max: capabilities.focusDistance.max,
                    step: capabilities.focusDistance.step,
                    label: 'Focus'
                }).on('change', ev => track.applyConstraints({ advanced: [{ focusDistance: ev.value }] }));
            }
        }

        setupCaptureButtons() {
            document.getElementById('capture-photo').onclick = () => this.capturePhoto();
            document.getElementById('record-video').onclick = () => {
                if (this.isRecording) this.stopRecording();
                else this.startRecording();
            };
        }

        capturePhoto() {
            const link = document.createElement('a');
            link.download = `CineCamPro_${Date.now()}.jpg`;
            link.href = this.canvas.toDataURL('image/jpeg', 0.9);
            link.click();
        }

        startRecording() {
            console.log("Starting recording...");
            this.isRecording = true;
            document.getElementById('record-video').textContent = 'Stop';
            document.getElementById('record-video').classList.add('recording');

            const recordedChunks = [];
            const canvasStream = this.canvas.captureStream(30);
            const audioTracks = this.stream.getAudioTracks();
            const combinedStream = new MediaStream([...canvasStream.getVideoTracks(), ...audioTracks]);

            this.mediaRecorder = new MediaRecorder(combinedStream, { mimeType: 'video/webm; codecs=vp9,opus' });
            this.mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) recordedChunks.push(e.data);
            };
            this.mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `CineCam_Recording_${Date.now()}.webm`;
                a.click();
                URL.revokeObjectURL(url);
            };
            this.mediaRecorder.start();
        }

        stopRecording() {
            console.log("Stopping recording.");
            this.isRecording = false;
            document.getElementById('record-video').textContent = 'Record';
            document.getElementById('record-video').classList.remove('recording');
            if (this.mediaRecorder) this.mediaRecorder.stop();
        }

        render() {
            if (!this.isRendering || this.video.paused || this.video.ended) {
                return;
            }

            const gl = this.gl;

            // 1. Update canvas size
            gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

            // 2. Update video texture
            gl.bindTexture(gl.TEXTURE_2D, this.texture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, this.video);

            // 3. Set uniforms (pass parameters to shader)
            gl.uniform1i(this.locations.uniforms.texture, 0);
            gl.uniform2f(this.locations.uniforms.resolution, gl.canvas.width, gl.canvas.height);
            gl.uniform1f(this.locations.uniforms.exposure, this.params.exposure);
            gl.uniform1f(this.locations.uniforms.contrast, this.params.contrast);
            gl.uniform1f(this.locations.uniforms.saturation, this.params.saturation);
            gl.uniform1f(this.locations.uniforms.temperature, this.params.temperature);
            gl.uniform1f(this.locations.uniforms.tint, this.params.tint);
            gl.uniform1f(this.locations.uniforms.sharpness, this.params.sharpness);
            gl.uniform1i(this.locations.uniforms.cinematicLook, this.params.cinematicLook ? 1 : 0);

            // 4. Draw the plane
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            
            // 5. Update Overlays
            this.updateOverlays();

            requestAnimationFrame(() => this.render());
        }

        updateOverlays() {
            const bars = document.querySelectorAll('#cinematic-bars .bar');
            const targetHeight = this.canvas.clientHeight / 2.35;
            const barHeight = (this.canvas.clientHeight - targetHeight) / 2;
            
            if (this.params.cinematicBars && barHeight > 0) {
                bars.forEach(bar => bar.style.height = `${barHeight}px`);
            } else {
                bars.forEach(bar => bar.style.height = '0px');
            }
        }
    }

    // --- App Entry Point ---
    document.addEventListener('DOMContentLoaded', () => {
        const app = new VirtualCamera();
        app.start();
    });
    </script>
</body>
</html>
